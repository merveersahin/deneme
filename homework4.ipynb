{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 4\n",
    "\n",
    "Use this notebook as a starter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data:\n",
    "\n",
    "- https://github.com/gastonstat/CreditScoring\n",
    "- Also available [here](https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-06-trees/CreditScoring.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-06-trees/CreditScoring.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation \n",
    "\n",
    "We'll talk about this dataset in more details in week 6. But for now, use the following code to get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('CreditScoring.csv')\n",
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the features are encoded as numbers. Use the following code to de-code them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_values = {\n",
    "    1: 'ok',\n",
    "    2: 'default',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.status = df.status.map(status_values)\n",
    "\n",
    "\n",
    "home_values = {\n",
    "    1: 'rent',\n",
    "    2: 'owner',\n",
    "    3: 'private',\n",
    "    4: 'ignore',\n",
    "    5: 'parents',\n",
    "    6: 'other',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.home = df.home.map(home_values)\n",
    "\n",
    "marital_values = {\n",
    "    1: 'single',\n",
    "    2: 'married',\n",
    "    3: 'widow',\n",
    "    4: 'separated',\n",
    "    5: 'divorced',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.marital = df.marital.map(marital_values)\n",
    "\n",
    "records_values = {\n",
    "    1: 'no',\n",
    "    2: 'yes',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.records = df.records.map(records_values)\n",
    "\n",
    "job_values = {\n",
    "    1: 'fixed',\n",
    "    2: 'partime',\n",
    "    3: 'freelance',\n",
    "    4: 'others',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.job = df.job.map(job_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the numerical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ['income', 'assets', 'debt']:\n",
    "    df[c] = df[c].replace(to_replace=99999999, value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove clients with unknown default status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.status != 'unk'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['default'] = (df.status == 'default').astype(int)\n",
    "del df['status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the categorical variables? What are the numerical?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seniority</th>\n",
       "      <th>home</th>\n",
       "      <th>time</th>\n",
       "      <th>age</th>\n",
       "      <th>marital</th>\n",
       "      <th>records</th>\n",
       "      <th>job</th>\n",
       "      <th>expenses</th>\n",
       "      <th>income</th>\n",
       "      <th>assets</th>\n",
       "      <th>debt</th>\n",
       "      <th>amount</th>\n",
       "      <th>price</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>rent</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>married</td>\n",
       "      <td>no</td>\n",
       "      <td>freelance</td>\n",
       "      <td>73</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>846</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>rent</td>\n",
       "      <td>60</td>\n",
       "      <td>58</td>\n",
       "      <td>widow</td>\n",
       "      <td>no</td>\n",
       "      <td>fixed</td>\n",
       "      <td>48</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1658</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>owner</td>\n",
       "      <td>36</td>\n",
       "      <td>46</td>\n",
       "      <td>married</td>\n",
       "      <td>yes</td>\n",
       "      <td>freelance</td>\n",
       "      <td>90</td>\n",
       "      <td>200</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>rent</td>\n",
       "      <td>60</td>\n",
       "      <td>24</td>\n",
       "      <td>single</td>\n",
       "      <td>no</td>\n",
       "      <td>fixed</td>\n",
       "      <td>63</td>\n",
       "      <td>182</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>1325</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>rent</td>\n",
       "      <td>36</td>\n",
       "      <td>26</td>\n",
       "      <td>single</td>\n",
       "      <td>no</td>\n",
       "      <td>fixed</td>\n",
       "      <td>46</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>310</td>\n",
       "      <td>910</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seniority   home  time  age  marital records        job  expenses  income  \\\n",
       "0          9   rent    60   30  married      no  freelance        73     129   \n",
       "1         17   rent    60   58    widow      no      fixed        48     131   \n",
       "2         10  owner    36   46  married     yes  freelance        90     200   \n",
       "3          0   rent    60   24   single      no      fixed        63     182   \n",
       "4          0   rent    36   26   single      no      fixed        46     107   \n",
       "\n",
       "   assets  debt  amount  price  default  \n",
       "0       0     0     800    846        0  \n",
       "1       0     0    1000   1658        0  \n",
       "2    3000     0    2000   2985        1  \n",
       "3    2500     0     900   1325        0  \n",
       "4       0     0     310    910        0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4454 entries, 0 to 4453\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   seniority  4454 non-null   int64 \n",
      " 1   home       4454 non-null   object\n",
      " 2   time       4454 non-null   int64 \n",
      " 3   age        4454 non-null   int64 \n",
      " 4   marital    4454 non-null   object\n",
      " 5   records    4454 non-null   object\n",
      " 6   job        4454 non-null   object\n",
      " 7   expenses   4454 non-null   int64 \n",
      " 8   income     4454 non-null   int64 \n",
      " 9   assets     4454 non-null   int64 \n",
      " 10  debt       4454 non-null   int64 \n",
      " 11  amount     4454 non-null   int64 \n",
      " 12  price      4454 non-null   int64 \n",
      " 13  default    4454 non-null   int32 \n",
      "dtypes: int32(1), int64(9), object(4)\n",
      "memory usage: 400.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns are: ['home', 'marital', 'records', 'job']\n",
      "Numerical columns are: ['seniority', 'time', 'age', 'expenses', 'income', 'assets', 'debt', 'amount', 'price']\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = list(df.dtypes[df.dtypes == 'object'].index)\n",
    "print('Categorical columns are:',categorical_columns)\n",
    "\n",
    "numerical_columns = list(df.dtypes[df.dtypes == 'int64'].index)\n",
    "print('Numerical columns are:',numerical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into 3 parts: train/validation/test with 60%/20%/20% distribution. Use `train_test_split` funciton for that with `random_state=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.2, random_state=1)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = df_train.default.values\n",
    "y_val = df_val.default.values\n",
    "y_test = df_test.default.values\n",
    "\n",
    "del df_train['default']\n",
    "del df_val['default']\n",
    "del df_test['default']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "ROC AUC could also be used to evaluate feature importance of numerical variables. \n",
    "\n",
    "Let's do that\n",
    "\n",
    "* For each numerical variable, use it as score and compute AUC with the \"default\" variable\n",
    "* Use the training dataset for that\n",
    "\n",
    "\n",
    "If your AUC is < 0.5, invert this variable by putting \"-\" in front\n",
    "\n",
    "(e.g. `-df_train['expenses']`)\n",
    "\n",
    "AUC can go below 0.5 if the variable is negatively correlated with the target varialble. You can change the direction of the correlation by negating this variable - then negative correlation becomes positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation btw target variable and seniority 0.2944527285893929\n",
      "Correlation btw target variable and time 0.5615415808350418\n",
      "Correlation btw target variable and age 0.43022102968591747\n",
      "Correlation btw target variable and expenses 0.5015186692958463\n",
      "Correlation btw target variable and income 0.325436518033204\n",
      "Correlation btw target variable and assets 0.3551349737979087\n",
      "Correlation btw target variable and debt 0.4948932221966698\n",
      "Correlation btw target variable and amount 0.5944773771486449\n",
      "Correlation btw target variable and price 0.5045483625527835\n"
     ]
    }
   ],
   "source": [
    "numericals = ['seniority', 'time', 'age', 'expenses', 'income', 'assets', 'debt', 'amount', 'price']\n",
    "for i in numericals:\n",
    "    print('Correlation btw target variable and', str(i), roc_auc_score(y_train, df_train[i]))\n",
    "#roc_auc_score(y_train, df_train['expenses'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which numerical variable (among the following 4) has the highest AUC?\n",
    "\n",
    "- seniority\n",
    "- time\n",
    "- income\n",
    "- debt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time has the highest correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "From now on, use these columns only:\n",
    "\n",
    "```\n",
    "['seniority', 'income', 'assets', 'records', 'job', 'home']\n",
    "```\n",
    "\n",
    "Apply one-hot-encoding using `DictVectorizer` and train the logistic regression with these parameters:\n",
    "\n",
    "```\n",
    "LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, solver='liblinear')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numericals = ['seniority', 'time', 'age', 'expenses', 'income', 'assets', 'debt', 'amount', 'price']\n",
    "categoricals = ['home', 'marital', 'records', 'job']\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "train_dict = df_train[categoricals + numericals].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "What's the AUC of this model on the validation dataset? (round to 3 digits)\n",
    "\n",
    "- 0.512\n",
    "- 0.612\n",
    "- 0.712\n",
    "- 0.812"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.811"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dict = df_val[categoricals + numericals].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dict)\n",
    "\n",
    "y_pred = model.predict_proba(X_val)[:, 1]\n",
    "default_decision = (y_pred >= 0.5)\n",
    "round((y_val == default_decision).mean(),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Now let's compute precision and recall for our model.\n",
    "\n",
    "* Evaluate the model on all thresholds from 0.0 to 1.0 with step 0.01\n",
    "* For each threshold, compute precision and recall\n",
    "* Plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_positive = (y_val == 1)\n",
    "actual_negative = (y_val == 0)\n",
    "\n",
    "t = 0.5\n",
    "predict_positive = (y_pred >= t)\n",
    "predict_negative = (y_pred < t)\n",
    "\n",
    "tp = (predict_positive & actual_positive).sum()\n",
    "tn = (predict_negative & actual_negative).sum()\n",
    "fp = (predict_positive & actual_negative).sum()\n",
    "fn = (predict_negative & actual_positive).sum()\n",
    "\n",
    "confusion_matrix = np.array([\n",
    "    [tn, fp],\n",
    "    [fn, tp]\n",
    "])\n",
    "\n",
    "\n",
    "#PRECISION AND RECALL\n",
    "p = tp / (tp + fp)\n",
    "r = tp / (tp + fn)\n",
    "\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "thresholds = np.linspace(0, 1, 101)\n",
    "\n",
    "for t in thresholds:\n",
    "    actual_positive = (y_val == 1)\n",
    "    actual_negative = (y_val == 0)\n",
    "    \n",
    "    predict_positive = (y_pred >= t)\n",
    "    predict_negative = (y_pred < t)\n",
    "\n",
    "    tp = (predict_positive & actual_positive).sum()\n",
    "    tn = (predict_negative & actual_negative).sum()\n",
    "\n",
    "    fp = (predict_positive & actual_negative).sum()\n",
    "    fn = (predict_negative & actual_positive).sum()\n",
    "    \n",
    "    scores.append((t, tp, fp, fn, tn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['threshold', 'tp', 'fp', 'fn', 'tn']\n",
    "df_scores = pd.DataFrame(scores, columns=columns)\n",
    "\n",
    "df_scores['tpr'] = df_scores.tp / (df_scores.tp + df_scores.fn)\n",
    "df_scores['fpr'] = df_scores.fp / (df_scores.fp + df_scores.tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xcbcc670>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_scores.threshold, df_scores['tpr'], label='TPR')\n",
    "plt.plot(df_scores.threshold, df_scores['fpr'], label='FPR')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At which threshold precision and recall curves intersect?\n",
    "\n",
    "* 0.2\n",
    "* 0.4\n",
    "* 0.6\n",
    "* 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Precision and recall are conflicting - when one grows, the other goes down. That's why they are often combined into the F1 score - a metrics that takes into account both\n",
    "\n",
    "This is the formula for computing F1:\n",
    "\n",
    "$$F_1 = 2 \\cdot \\cfrac{P \\cdot R}{P + R}$$\n",
    "\n",
    "Where $P$ is precision and $R$ is recall.\n",
    "\n",
    "Let's compute F1 for all thresholds from 0.0 to 1.0 with increment 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.42951541850220265\n",
      "0.01 0.4372197309417041\n",
      "0.02 0.4470046082949309\n",
      "0.03 0.46080760095011875\n",
      "0.04 0.4695863746958638\n",
      "0.05 0.48675914249684743\n",
      "0.06 0.500651890482399\n",
      "0.07 0.5092838196286471\n",
      "0.08 0.5196211096075778\n",
      "0.09 0.5294117647058824\n",
      "0.1 0.5386819484240688\n",
      "0.11 0.551622418879056\n",
      "0.12 0.562406015037594\n",
      "0.13 0.5745007680491552\n",
      "0.14 0.579937304075235\n",
      "0.15 0.585209003215434\n",
      "0.16 0.5905383360522022\n",
      "0.17 0.5956738768718802\n",
      "0.18 0.6061643835616438\n",
      "0.19 0.6188811188811189\n",
      "0.2 0.6247755834829443\n",
      "0.21 0.629090909090909\n",
      "0.22 0.6382189239332097\n",
      "0.23 0.6450381679389314\n",
      "0.24 0.6562500000000001\n",
      "0.25 0.66\n",
      "0.26 0.6680244399185336\n",
      "0.27 0.6666666666666666\n",
      "0.28 0.6609808102345415\n",
      "0.29 0.6609071274298056\n",
      "0.3 0.6593406593406593\n",
      "0.31 0.65625\n",
      "0.32 0.6545454545454547\n",
      "0.33 0.6528735632183909\n",
      "0.34 0.6542923433874709\n",
      "0.35000000000000003 0.6555819477434679\n",
      "0.36 0.6521739130434783\n",
      "0.37 0.653658536585366\n",
      "0.38 0.6469135802469136\n",
      "0.39 0.6482412060301507\n",
      "0.4 0.6361323155216285\n",
      "0.41000000000000003 0.6373056994818653\n",
      "0.42 0.6263157894736842\n",
      "0.43 0.619047619047619\n",
      "0.44 0.6199460916442049\n",
      "0.45 0.6246575342465753\n",
      "0.46 0.6204986149584487\n",
      "0.47000000000000003 0.6106442577030812\n",
      "0.48 0.6079545454545455\n",
      "0.49 0.6149425287356322\n",
      "0.5 0.6064139941690962\n",
      "0.51 0.5892857142857143\n",
      "0.52 0.5783132530120483\n",
      "0.53 0.5740181268882174\n",
      "0.54 0.5714285714285714\n",
      "0.55 0.5679012345679012\n",
      "0.56 0.5660377358490567\n",
      "0.5700000000000001 0.5530546623794212\n",
      "0.58 0.5407166123778501\n",
      "0.59 0.5377049180327869\n",
      "0.6 0.5217391304347827\n",
      "0.61 0.4931506849315069\n",
      "0.62 0.48965517241379314\n",
      "0.63 0.4771929824561402\n",
      "0.64 0.46808510638297873\n",
      "0.65 0.45323741007194246\n",
      "0.66 0.4492753623188405\n",
      "0.67 0.42804428044280446\n",
      "0.68 0.4237918215613383\n",
      "0.6900000000000001 0.4015151515151515\n",
      "0.7000000000000001 0.39543726235741444\n",
      "0.71 0.3923076923076923\n",
      "0.72 0.36000000000000004\n",
      "0.73 0.326530612244898\n",
      "0.74 0.2784810126582279\n",
      "0.75 0.2723404255319149\n",
      "0.76 0.25\n",
      "0.77 0.24242424242424238\n",
      "0.78 0.21145374449339208\n",
      "0.79 0.21145374449339208\n",
      "0.8 0.21238938053097345\n",
      "0.81 0.19819819819819817\n",
      "0.8200000000000001 0.1900452488687783\n",
      "0.8300000000000001 0.1743119266055046\n",
      "0.84 0.1574074074074074\n",
      "0.85 0.14883720930232558\n",
      "0.86 0.14018691588785048\n",
      "0.87 0.12322274881516589\n",
      "0.88 0.1142857142857143\n",
      "0.89 0.08695652173913043\n",
      "0.9 0.07804878048780488\n",
      "0.91 0.07804878048780488\n",
      "0.92 0.030000000000000002\n",
      "0.93 0.030000000000000002\n",
      "0.9400000000000001 0.030000000000000002\n",
      "0.9500000000000001 0.030150753768844223\n",
      "0.96 0.010152284263959392\n",
      "0.97 0.010204081632653062\n",
      "0.98 nan\n",
      "0.99 nan\n",
      "1.0 nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\merve\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.linspace(0, 1, 101) \n",
    "\n",
    "for t in thresholds:\n",
    "    actual_positive = (y_val == 1)\n",
    "    actual_negative = (y_val == 0)\n",
    "    \n",
    "    predict_positive = (y_pred >= t)\n",
    "    predict_negative = (y_pred < t)\n",
    "\n",
    "    tp = (predict_positive & actual_positive).sum()\n",
    "    tn = (predict_negative & actual_negative).sum()\n",
    "\n",
    "    fp = (predict_positive & actual_negative).sum()\n",
    "    fn = (predict_negative & actual_positive).sum()\n",
    "    \n",
    "    p = tp / (tp + fp)\n",
    "    r = tp / (tp + fn)\n",
    "    \n",
    "    f1 = 2* ((p*r)/(p+r))\n",
    "    print(t, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At which threshold F1 is maximal?\n",
    "\n",
    "- 0.1\n",
    "- 0.3\n",
    "- 0.5\n",
    "- 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "\n",
    "Use the `KFold` class from Scikit-Learn to evaluate our model on 5 different folds:\n",
    "\n",
    "```\n",
    "KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "```\n",
    "\n",
    "* Iterate over different folds of `df_full_train`\n",
    "* Split the data into train and validation\n",
    "* Train the model on train with these parameters: `LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)`\n",
    "* Use AUC to evaluate the model on validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2851, 713)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "train_id, val_idx = next(kf.split(df_full_train))\n",
    "\n",
    "len(train_idx),len(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df_train, y_train, C=1.0):\n",
    "    dicts = df_train[categoricals + numericals].to_dict(orient='records')\n",
    "\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dicts)\n",
    "\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return dv, model\n",
    "\n",
    "def predict(df, dv, model):\n",
    "    dicts = df[categoricals + numericals].to_dict(orient='records')\n",
    "\n",
    "    X = dv.transform(dicts)\n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "y_pred = predict(df_val, dv, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for train_idx, val_idx in kfold.split(df_full_train):\n",
    "    df_train = df_full_train.iloc[train_idx]\n",
    "    df_val = df_full_train.iloc[val_idx]\n",
    "    \n",
    "    y_train = df_train.default.values\n",
    "    y_val = df_val.default.values\n",
    "    \n",
    "    dv, model = train(df_train, y_train)\n",
    "    y_pred = predict(df_val, dv, model)\n",
    "    \n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    scores.append(auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017312816081385476"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How large is standard devidation of the scores across different folds?\n",
    "\n",
    "- 0.001\n",
    "- 0.014\n",
    "- 0.09\n",
    "- 0.14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Now let's use 5-Fold cross-validation to find the best parameter C\n",
    "\n",
    "* Iterate over the following C values: `[0.01, 0.1, 1, 10]`\n",
    "* Initialize `KFold` with the same parameters as previously\n",
    "* Use these parametes for the model: `LogisticRegression(solver='liblinear', C=C, max_iter=1000)`\n",
    "* Compute the mean score as well as the std (round the mean and std to 3 decimal digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "364f8a3b574240998411202a83dc0a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.01 0.835 +- 0.019\n",
      "C=0.1 0.844 +- 0.017\n",
      "C=1 0.844 +- 0.017\n",
      "C=10 0.844 +- 0.017\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "n_splits = 5\n",
    "\n",
    "for C in tqdm([0.01, 0.1, 1, 10]):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(df_full_train):\n",
    "        df_train = df_full_train.iloc[train_idx]\n",
    "        df_val = df_full_train.iloc[val_idx]\n",
    "\n",
    "        y_train = df_train.default.values\n",
    "        y_val = df_val.default.values\n",
    "\n",
    "        dv, model = train(df_train, y_train, C=C)\n",
    "        y_pred = predict(df_val, dv, model)\n",
    "\n",
    "        auc = roc_auc_score(y_val, y_pred)\n",
    "        scores.append(auc)\n",
    "\n",
    "    print('C=%s %.3f +- %.3f' % (C, np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8555192555192555,\n",
       " 0.8631487992372326,\n",
       " 0.8293543244320446,\n",
       " 0.853368313485045,\n",
       " 0.8187416635922468]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which C leads to the best mean score?\n",
    "\n",
    "- 0.01\n",
    "- 0.1\n",
    "- 1\n",
    "- 10\n",
    "\n",
    "If you have ties, select the score with the lowest std. If you still have ties, select the smallest C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C= 10 leads to best mean score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the results\n",
    "\n",
    "Submit your results here: https://forms.gle/e497sR5iB36mM9Cs5\n",
    "\n",
    "It's possible that your answers won't match exactly. If it's the case, select the closest one.\n",
    "\n",
    "## Deadline\n",
    "\n",
    "The deadline for submitting is 04 October 2021, 17:00 CET. After that, the form will be closed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
